# -*- coding: utf-8 -*-
"""Tarea 2 IA

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z8NLSwF5TMBw_vkfmrFRUau43HICJUIl

# Universidad de O'Higgins

## Escuela de Ingeniería
## COM4402: Introducción a Inteligencia Artificial

### **Tarea 2: Clasificación de Dígitos Manuscritos con Redes Neuronales**

### Estudiante: Jairo Donoso Jiménez

El objetivo de esta tarea es utilizar redes neuronales en un problema de clasificación de dígitos. Se utilizará el conjunto de datos Optical Recognition of Handwritten Digits Data Set. Este conjunto tiene 64 características, con 10 clases y 5620 muestras en total. La base de datos estará disponible en U-Campus.

Las redes a ser entrenadas tienen la siguiente estructura: capa de entrada de dimensionalidad 64 (correspondiente a los datos de entrada), capas ocultas (una o dos) y capa de salida con 10 neuronas y función de activación softmax. La función de loss (pérdida) es entropía cruzada. El optimizador que se
debe usar es Adam. La función softmax está implícita al usar la función de pérdida CrossEntropyLoss de PyTorch (**no se debe agregar softmax a la salida de la red**).

Se usará PyTorch para entrenar y validar la red neuronal que implementa el clasificador de dígitos. Se analizará los efectos de cambiar el tamaño de la red (número de capas ocultas y de neuronas en estas
capas) y la función de activación.

El siguiente código base debe ser usado para realizar las actividades pedidas.

## Observación: Antes de ejecutar su código, active el uso de GPU en Google Colab para acelerar el proceso de entrenamiento.

### Para esto: vaya a "Entorno de Ejecución" en el menú superior, haga click en "Cambiar tipo de entorno de ejecución", y seleccionar/verificar "GPU" en "Acelerador de Hardware"
"""

import pandas as pd
import torch
import torch.nn as nn
import numpy as np
import time
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score
import seaborn as sns

"""## Subir datasets de dígitos (train)"""

# Datos de entrenamiento
!wget https://raw.githubusercontent.com/Felipe1401/Mineria/main/dataset_digits/1_digits_train.txt

# Datos de validación
!wget https://raw.githubusercontent.com/Felipe1401/Mineria/main/dataset_digits/1_digits_test.txt

"""## Leer dataset de dígitos"""

column_names = ["feat" + str(i) for i in range(64)]
column_names.append("class")

df_train_val = pd.read_csv('1_digits_train.txt', names = column_names)
df_train_val

df_test = pd.read_csv('1_digits_test.txt', names = column_names)
df_test

df_train, df_val = train_test_split(df_train_val, test_size = 0.3, random_state = 10)

scaler = StandardScaler().fit(df_train.iloc[:,0:64])
df_train.iloc[:,0:64] = scaler.transform(df_train.iloc[:,0:64])
df_val.iloc[:,0:64] = scaler.transform(df_val.iloc[:,0:64])
df_test.iloc[:,0:64] = scaler.transform(df_test.iloc[:,0:64])

df_train

"""## Crear datasets y dataloaders para pytorch (train)"""

# Crear datasets
feats_train = df_train.to_numpy()[:,0:64].astype(np.float32)
labels_train = df_train.to_numpy()[:,64].astype(int)
dataset_train = [ {"features":feats_train[i,:], "labels":labels_train[i]} for i in range(feats_train.shape[0]) ]

feats_val = df_val.to_numpy()[:,0:64].astype(np.float32)
labels_val = df_val.to_numpy()[:,64].astype(int)
dataset_val = [ {"features":feats_val[i,:], "labels":labels_val[i]} for i in range(feats_val.shape[0]) ]

feats_test = df_test.to_numpy()[:,0:64].astype(np.float32)
labels_test = df_test.to_numpy()[:,64].astype(int)
dataset_test = [ {"features":feats_test[i,:], "labels":labels_test[i]} for i in range(feats_test.shape[0]) ]

# Crear dataloaders
dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=128, shuffle=True, num_workers=0)
dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=128, shuffle=True, num_workers=0)
dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=128, shuffle=True, num_workers=0)

"""## Entrenamiento

## Modelo a)
"""

### Modelo a) ###

# -- Modelo de una capa oculta con 10 neuronas y activación ReLU --
# Capa de entrada de 64 neuronas (porque hay 64 características)
# Capa oculta de 10 neuronas con activación ReLU
# Capa de salida de 10 neuronas (porque hay 10 clases)

modela = nn.Sequential(
          nn.Linear(64, 10),
          nn.ReLU(),
          nn.Linear(10,10)
        )

# Se le indica a Pytorch que correremos el modelo con GPU
device = "cuda" if torch.cuda.is_available() else "cpu"
modela = modela.to(device)

# Definimos la función de pérdida y optimizador usaremos
criterion = nn.CrossEntropyLoss()                         # Función de pérdida
optimizer = torch.optim.Adam(modela.parameters(), lr=1e-3) # Optimizador

start = time.time()

# Guardar resultados del loss y epocas que duró el entrenamiento
loss_train = []
loss_val = []
epochs = []

patience = 20  # Número de épocas para esperar antes de detener el entrenamiento, sacado a través de graficar 250 épocas
counter = 0     # Contador para llevar el registro de la paciencia
best_val_loss = float('inf')  # Inicializar el mejor loss de validación con un valor infinito

# Entrenamiento de la red por n epocas
for epoch in range(1000):

  # Guardar loss de cada batch
  loss_train_batches = []
  loss_val_batches = []


  # Entrenamiento --------------------------------------------------------------
  modela.train()
  # Debemos recorrer cada batch (lote de los datos)
  for i, data in enumerate(dataloader_train, 0):
    # Procesar batch actual
    inputs = data["features"].to(device) # Características
    labels = data["labels"].to(device)   # Clases
    # zero the parameter gradients
    optimizer.zero_grad()
    # forward + backward + optimize
    outputs = modela(inputs)           # Predicciones
    loss = criterion(outputs, labels) # Loss de entrenamiento
    loss.backward()                   # Backpropagation
    optimizer.step()

    # Guardamos la pérdida de entrenamiento y el accuracy en el batch actual
    loss_train_batches.append(loss.item())

  # Guardamos el loss de entrenamiento de la época actual
  loss_train.append(np.mean(loss_train_batches)) # Loss promedio de los batches

  # Predicción en conjunto de validación ---------------------------------------
  modela.eval()
  with torch.no_grad():
    # Iteramos dataloader_val para evaluar el modelo en los datos de validación
    for i, data in enumerate(dataloader_val, 0):
      # Procesar batch actual
      inputs = data["features"].to(device) # Características
      labels = data["labels"].to(device)   # Clases

      outputs = modela(inputs)              # Obtenemos predicciones

      # Guardamos la pérdida de validación en el batch actual
      loss = criterion(outputs, labels)
      loss_val_batches.append(loss.item())

  # Guardamos el Loss de validación de la época actual
  loss_val.append(np.mean(loss_val_batches)) # Loss promedio de los batches

  # Guardamos la época
  epochs.append(epoch)

  # Imprimir la pérdida de entrenamiento/validación en la época actual
  print(("Epoch: %d, train loss: %.4f, val loss: %.4f"  %(epoch, loss_train[epoch], loss_val[epoch])))

  # Tenemos el loss de entrenamiento y validación, ¿Como sería el early-stopping?
  # Verificamos si el loss de validación mejora
  if loss_val[-1] < best_val_loss:
        best_val_loss = loss_val[-1]
        counter = 0  # Reiniciamos el contador si hay mejora
  else:
        counter += 1  # Incrementamos el contador si no hay mejora

        # Si hemos alcanzado la paciencia, detenemos el entrenamiento
        if counter >= patience:
            print('Early stopping at epoch', epoch)
            break

end = time.time()
print('Finished Training, total time %f seconds' % (end - start))


# Graficar loss de entrenamiento Y validación
plt.figure(figsize = (8, 5))
plt.title('Modelo a loss on train & validation')
plt.xlabel('No. epochs')
plt.ylabel('Loss')
plt.plot(epochs, loss_train, 'b', label = 'Train')
plt.plot(epochs, loss_val, 'r', label = 'Validation')
plt.grid()
plt.legend()

# Obtener las predicciones en el conjunto de entrenamiento
modela.eval()
all_predictions = []
all_labels = []

with torch.no_grad():
    for data in dataloader_train:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = modela(inputs)
        _, predicted = torch.max(outputs, 1)
        all_predictions.extend(predicted.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# Calcular la matriz de confusión normalizada
conf_matrix = confusion_matrix(all_labels, all_predictions, normalize='true')

# Calcular el accuracy normalizado
normalized_accuracy = accuracy_score(all_labels, all_predictions)

# Mostrar la matriz de confusión con colores basados en el accuracy
def plot_confusion_matrix(matrix, accuracy, ax):
    sns.heatmap(matrix, annot=True, fmt='.2f', cmap='Blues', cbar=False, ax=ax)
    ax.set_xlabel('Predicted labels')
    ax.set_ylabel('True labels')
    ax.set_title(f'Normalized Confusion Matrix\nAccuracy train modelo a: {accuracy:.2f}')

# Graficar la matriz de confusión
plt.figure(figsize=(8, 6))
plot_confusion_matrix(conf_matrix, normalized_accuracy, plt.gca())
plt.show()

# Obtener las predicciones en el conjunto de validación
modela.eval()
all_predictions_val = []
all_labels_val = []

with torch.no_grad():
    for data in dataloader_val:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = modela(inputs)
        _, predicted = torch.max(outputs, 1)
        all_predictions_val.extend(predicted.cpu().numpy())
        all_labels_val.extend(labels.cpu().numpy())

# Calcular la matriz de confusión normalizada para el conjunto de validación
conf_matrix_val = confusion_matrix(all_labels_val, all_predictions_val, normalize='true')

# Calcular el accuracy normalizado para el conjunto de validación
normalized_accuracy_val = accuracy_score(all_labels_val, all_predictions_val)

# Función para mostrar la matriz de confusión con colores basados en el accuracy
def plot_confusion_matrix(matrix, accuracy, ax):
    sns.heatmap(matrix, annot=True, fmt='.2f', cmap='Blues', cbar=False, ax=ax)
    ax.set_xlabel('Predicted labels')
    ax.set_ylabel('True labels')
    ax.set_title(f'Normalized Confusion Matrix\nAccuracy eval modelo a: {accuracy:.2f}')

# Mostrar la matriz de confusión con colores basados en el accuracy para el conjunto de validación
plt.figure(figsize=(8, 6))
plot_confusion_matrix(conf_matrix_val, normalized_accuracy_val, plt.gca())
plt.show()

"""## Modelo b)"""

### Modelo b) ###

# -- Modelo de una capa oculta con 10 neuronas y activación ReLU --
# Capa de entrada de 64 neuronas (porque hay 64 características)
# Capa oculta de 40 neuronas con activación ReLU
# Capa de salida de 10 neuronas (porque hay 10 clases)

modelb = nn.Sequential(
          nn.Linear(64,40 ),
          nn.ReLU(),
          nn.Linear(40,10)
        )

# Se le indica a Pytorch que correremos el modelo con GPU
device = "cuda" if torch.cuda.is_available() else "cpu"
modelb = modelb.to(device)

# Definimos la función de pérdida y optimizador usaremos
criterion = nn.CrossEntropyLoss()                         # Función de pérdida
optimizer = torch.optim.Adam(modelb.parameters(), lr=1e-3) # Optimizador

start = time.time()

# Guardar resultados del loss y epocas que duró el entrenamiento
loss_train = []
loss_val = []
epochs = []

patience = 15  # Número de épocas para esperar antes de detener el entrenamiento, sacado a través de graficar 250 épocas
counter = 0     # Contador para llevar el registro de la paciencia
best_val_loss = float('inf')  # Inicializar el mejor loss de validación con un valor infinito

# Entrenamiento de la red por n epocas
for epoch in range(1000):

  # Guardar loss de cada batch
  loss_train_batches = []
  loss_val_batches = []


  # Entrenamiento --------------------------------------------------------------
  modelb.train()
  # Debemos recorrer cada batch (lote de los datos)
  for i, data in enumerate(dataloader_train, 0):
    # Procesar batch actual
    inputs = data["features"].to(device) # Características
    labels = data["labels"].to(device)   # Clases
    # zero the parameter gradients
    optimizer.zero_grad()
    # forward + backward + optimize
    outputs = modelb(inputs)           # Predicciones
    loss = criterion(outputs, labels) # Loss de entrenamiento
    loss.backward()                   # Backpropagation
    optimizer.step()

    # Guardamos la pérdida de entrenamiento y el accuracy en el batch actual
    loss_train_batches.append(loss.item())

  # Guardamos el loss de entrenamiento de la época actual
  loss_train.append(np.mean(loss_train_batches)) # Loss promedio de los batches

  # Predicción en conjunto de validación ---------------------------------------
  modelb.eval()
  with torch.no_grad():
    # Iteramos dataloader_val para evaluar el modelo en los datos de validación
    for i, data in enumerate(dataloader_val, 0):
      # Procesar batch actual
      inputs = data["features"].to(device) # Características
      labels = data["labels"].to(device)   # Clases

      outputs = modelb(inputs)              # Obtenemos predicciones

      # Guardamos la pérdida de validación en el batch actual
      loss = criterion(outputs, labels)
      loss_val_batches.append(loss.item())

  # Guardamos el Loss de validación de la época actual
  loss_val.append(np.mean(loss_val_batches)) # Loss promedio de los batches

  # Guardamos la época
  epochs.append(epoch)

  # Imprimir la pérdida de entrenamiento/validación en la época actual
  print(("Epoch: %d, train loss: %.4f, val loss: %.4f"  %(epoch, loss_train[epoch], loss_val[epoch])))

  # Tenemos el loss de entrenamiento y validación, ¿Como sería el early-stopping?
  # Verificamos si el loss de validación mejora
  if loss_val[-1] < best_val_loss:
        best_val_loss = loss_val[-1]
        counter = 0  # Reiniciamos el contador si hay mejora
  else:
        counter += 1  # Incrementamos el contador si no hay mejora

        # Si hemos alcanzado la paciencia, detenemos el entrenamiento
        if counter >= patience:
            print('Early stopping at epoch', epoch)
            break

end = time.time()
print('Finished Training, total time %f seconds' % (end - start))


# Graficar loss de entrenamiento Y validación
plt.figure(figsize = (8, 5))
plt.title('Modelo b loss on train & validation')
plt.xlabel('No. epochs')
plt.ylabel('Loss')
plt.plot(epochs, loss_train, 'b', label = 'Train')
plt.plot(epochs, loss_val, 'r', label = 'Validation')
plt.grid()
plt.legend()

# Obtener las predicciones en el conjunto de entrenamiento
modelb.eval()
all_predictions = []
all_labels = []

with torch.no_grad():
    for data in dataloader_train:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = modelb(inputs)
        _, predicted = torch.max(outputs, 1)
        all_predictions.extend(predicted.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# Calcular la matriz de confusión normalizada
conf_matrix = confusion_matrix(all_labels, all_predictions, normalize='true')

# Calcular el accuracy normalizado
normalized_accuracy = accuracy_score(all_labels, all_predictions)

# Mostrar la matriz de confusión con colores basados en el accuracy
def plot_confusion_matrix(matrix, accuracy, ax):
    sns.heatmap(matrix, annot=True, fmt='.2f', cmap='Blues', cbar=False, ax=ax)
    ax.set_xlabel('Predicted labels')
    ax.set_ylabel('True labels')
    ax.set_title(f'Normalized Confusion Matrix\nAccuracy train modelo b: {accuracy:.2f}')

# Graficar la matriz de confusión
plt.figure(figsize=(8, 6))
plot_confusion_matrix(conf_matrix, normalized_accuracy, plt.gca())
plt.show()

# Obtener las predicciones en el conjunto de validación
modelb.eval()
all_predictions_val = []
all_labels_val = []

with torch.no_grad():
    for data in dataloader_val:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = modelb(inputs)
        _, predicted = torch.max(outputs, 1)
        all_predictions_val.extend(predicted.cpu().numpy())
        all_labels_val.extend(labels.cpu().numpy())

# Calcular la matriz de confusión normalizada para el conjunto de validación
conf_matrix_val = confusion_matrix(all_labels_val, all_predictions_val, normalize='true')

# Calcular el accuracy normalizado para el conjunto de validación
normalized_accuracy_val = accuracy_score(all_labels_val, all_predictions_val)

# Función para mostrar la matriz de confusión con colores basados en el accuracy
def plot_confusion_matrix(matrix, accuracy, ax):
    sns.heatmap(matrix, annot=True, fmt='.2f', cmap='Blues', cbar=False, ax=ax)
    ax.set_xlabel('Predicted labels')
    ax.set_ylabel('True labels')
    ax.set_title(f'Normalized Confusion Matrix\nAccuracy eval modelo b: {accuracy:.2f}')

# Mostrar la matriz de confusión con colores basados en el accuracy para el conjunto de validación
plt.figure(figsize=(8, 6))
plot_confusion_matrix(conf_matrix_val, normalized_accuracy_val, plt.gca())
plt.show()

"""## Modelo c"""

### Modelo c) ###

# -- Modelo de una capa oculta con 10 neuronas y activación Tanh --
# Capa de entrada de 64 neuronas (porque hay 64 características)
# Capa oculta de 10 neuronas con activación ReLU
# Capa de salida de 10 neuronas (porque hay 10 clases)

modelc = nn.Sequential(
          nn.Linear(64,10 ),
          nn.Tanh(),
          nn.Linear(10,10)
        )

# Se le indica a Pytorch que correremos el modelo con GPU
device = "cuda" if torch.cuda.is_available() else "cpu"
modelc = modelc.to(device)

# Definimos la función de pérdida y optimizador usaremos
criterion = nn.CrossEntropyLoss()                         # Función de pérdida
optimizer = torch.optim.Adam(modelc.parameters(), lr=1e-3) # Optimizador

start = time.time()

# Guardar resultados del loss y epocas que duró el entrenamiento
loss_train = []
loss_val = []
epochs = []

patience = 10  # Número de épocas para esperar antes de detener el entrenamiento, sacado a través de graficar 250 épocas
counter = 0     # Contador para llevar el registro de la paciencia
best_val_loss = float('inf')  # Inicializar el mejor loss de validación con un valor infinito

# Entrenamiento de la red por n epocas
for epoch in range(1000):

  # Guardar loss de cada batch
  loss_train_batches = []
  loss_val_batches = []


  # Entrenamiento --------------------------------------------------------------
  modelc.train()
  # Debemos recorrer cada batch (lote de los datos)
  for i, data in enumerate(dataloader_train, 0):
    # Procesar batch actual
    inputs = data["features"].to(device) # Características
    labels = data["labels"].to(device)   # Clases
    # zero the parameter gradients
    optimizer.zero_grad()
    # forward + backward + optimize
    outputs = modelc(inputs)           # Predicciones
    loss = criterion(outputs, labels) # Loss de entrenamiento
    loss.backward()                   # Backpropagation
    optimizer.step()

    # Guardamos la pérdida de entrenamiento y el accuracy en el batch actual
    loss_train_batches.append(loss.item())

  # Guardamos el loss de entrenamiento de la época actual
  loss_train.append(np.mean(loss_train_batches)) # Loss promedio de los batches

  # Predicción en conjunto de validación ---------------------------------------
  modelc.eval()
  with torch.no_grad():
    # Iteramos dataloader_val para evaluar el modelo en los datos de validación
    for i, data in enumerate(dataloader_val, 0):
      # Procesar batch actual
      inputs = data["features"].to(device) # Características
      labels = data["labels"].to(device)   # Clases

      outputs = modelc(inputs)              # Obtenemos predicciones

      # Guardamos la pérdida de validación en el batch actual
      loss = criterion(outputs, labels)
      loss_val_batches.append(loss.item())

  # Guardamos el Loss de validación de la época actual
  loss_val.append(np.mean(loss_val_batches)) # Loss promedio de los batches

  # Guardamos la época
  epochs.append(epoch)

  # Imprimir la pérdida de entrenamiento/validación en la época actual
  print(("Epoch: %d, train loss: %.4f, val loss: %.4f"  %(epoch, loss_train[epoch], loss_val[epoch])))

  # Tenemos el loss de entrenamiento y validación, ¿Como sería el early-stopping?
  # Verificamos si el loss de validación mejora
  if loss_val[-1] < best_val_loss:
        best_val_loss = loss_val[-1]
        counter = 0  # Reiniciamos el contador si hay mejora
  else:
        counter += 1  # Incrementamos el contador si no hay mejora

        # Si hemos alcanzado la paciencia, detenemos el entrenamiento
        if counter >= patience:
            print('Early stopping at epoch', epoch)
            break

end = time.time()
print('Finished Training, total time %f seconds' % (end - start))


# Graficar loss de entrenamiento Y validación
plt.figure(figsize = (8, 5))
plt.title('Modelo c loss on train & validation')
plt.xlabel('No. epochs')
plt.ylabel('Loss')
plt.plot(epochs, loss_train, 'b', label = 'Train')
plt.plot(epochs, loss_val, 'r', label = 'Validation')
plt.grid()
plt.legend()

# Obtener las predicciones en el conjunto de entrenamiento
modelc.eval()
all_predictions = []
all_labels = []

with torch.no_grad():
    for data in dataloader_train:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = modelc(inputs)
        _, predicted = torch.max(outputs, 1)
        all_predictions.extend(predicted.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# Calcular la matriz de confusión normalizada
conf_matrix = confusion_matrix(all_labels, all_predictions, normalize='true')

# Calcular el accuracy normalizado
normalized_accuracy = accuracy_score(all_labels, all_predictions)

# Mostrar la matriz de confusión con colores basados en el accuracy
def plot_confusion_matrix(matrix, accuracy, ax):
    sns.heatmap(matrix, annot=True, fmt='.2f', cmap='Blues', cbar=False, ax=ax)
    ax.set_xlabel('Predicted labels')
    ax.set_ylabel('True labels')
    ax.set_title(f'Normalized Confusion Matrix\nAccuracy train modelo c: {accuracy:.2f}')

# Graficar la matriz de confusión
plt.figure(figsize=(8, 6))
plot_confusion_matrix(conf_matrix, normalized_accuracy, plt.gca())
plt.show()

# Obtener las predicciones en el conjunto de validación
modelc.eval()
all_predictions_val = []
all_labels_val = []

with torch.no_grad():
    for data in dataloader_val:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = modelc(inputs)
        _, predicted = torch.max(outputs, 1)
        all_predictions_val.extend(predicted.cpu().numpy())
        all_labels_val.extend(labels.cpu().numpy())

# Calcular la matriz de confusión normalizada para el conjunto de validación
conf_matrix_val = confusion_matrix(all_labels_val, all_predictions_val, normalize='true')

# Calcular el accuracy normalizado para el conjunto de validación
normalized_accuracy_val = accuracy_score(all_labels_val, all_predictions_val)

# Función para mostrar la matriz de confusión con colores basados en el accuracy
def plot_confusion_matrix(matrix, accuracy, ax):
    sns.heatmap(matrix, annot=True, fmt='.2f', cmap='Blues', cbar=False, ax=ax)
    ax.set_xlabel('Predicted labels')
    ax.set_ylabel('True labels')
    ax.set_title(f'Normalized Confusion Matrix\nAccuracy eval modelo c: {accuracy:.2f}')

# Mostrar la matriz de confusión con colores basados en el accuracy para el conjunto de validación
plt.figure(figsize=(8, 6))
plot_confusion_matrix(conf_matrix_val, normalized_accuracy_val, plt.gca())
plt.show()

"""## Modelo d)"""

### Modelo d) ###

# -- Modelo de una capa oculta con 10 neuronas y activación Tanh --
# Capa de entrada de 64 neuronas (porque hay 64 características)
# Capa oculta de 40 neuronas con activación Tanh
# Capa de salida de 10 neuronas (porque hay 10 clases)

modeld = nn.Sequential(
          nn.Linear(64,40),
          nn.Tanh(),
          nn.Linear(40,10)
        )

# Se le indica a Pytorch que correremos el modelo con GPU
device = "cuda" if torch.cuda.is_available() else "cpu"
modeld = modeld.to(device)

# Definimos la función de pérdida y optimizador usaremos
criterion = nn.CrossEntropyLoss()                         # Función de pérdida
optimizer = torch.optim.Adam(modeld.parameters(), lr=1e-3) # Optimizador

start = time.time()

# Guardar resultados del loss y epocas que duró el entrenamiento
loss_train = []
loss_val = []
epochs = []

patience = 25  # Número de épocas para esperar antes de detener el entrenamiento, sacado a través de graficar 250 épocas
counter = 0     # Contador para llevar el registro de la paciencia
best_val_loss = float('inf')  # Inicializar el mejor loss de validación con un valor infinito

# Entrenamiento de la red por n epocas
for epoch in range(1000):

  # Guardar loss de cada batch
  loss_train_batches = []
  loss_val_batches = []


  # Entrenamiento --------------------------------------------------------------
  modeld.train()
  # Debemos recorrer cada batch (lote de los datos)
  for i, data in enumerate(dataloader_train, 0):
    # Procesar batch actual
    inputs = data["features"].to(device) # Características
    labels = data["labels"].to(device)   # Clases
    # zero the parameter gradients
    optimizer.zero_grad()
    # forward + backward + optimize
    outputs = modeld(inputs)           # Predicciones
    loss = criterion(outputs, labels) # Loss de entrenamiento
    loss.backward()                   # Backpropagation
    optimizer.step()

    # Guardamos la pérdida de entrenamiento y el accuracy en el batch actual
    loss_train_batches.append(loss.item())

  # Guardamos el loss de entrenamiento de la época actual
  loss_train.append(np.mean(loss_train_batches)) # Loss promedio de los batches

  # Predicción en conjunto de validación ---------------------------------------
  modeld.eval()
  with torch.no_grad():
    # Iteramos dataloader_val para evaluar el modelo en los datos de validación
    for i, data in enumerate(dataloader_val, 0):
      # Procesar batch actual
      inputs = data["features"].to(device) # Características
      labels = data["labels"].to(device)   # Clases

      outputs = modeld(inputs)              # Obtenemos predicciones

      # Guardamos la pérdida de validación en el batch actual
      loss = criterion(outputs, labels)
      loss_val_batches.append(loss.item())

  # Guardamos el Loss de validación de la época actual
  loss_val.append(np.mean(loss_val_batches)) # Loss promedio de los batches

  # Guardamos la época
  epochs.append(epoch)

  # Imprimir la pérdida de entrenamiento/validación en la época actual
  print(("Epoch: %d, train loss: %.4f, val loss: %.4f"  %(epoch, loss_train[epoch], loss_val[epoch])))

  # Tenemos el loss de entrenamiento y validación, ¿Como sería el early-stopping?
  # Verificamos si el loss de validación mejora
  if loss_val[-1] < best_val_loss:
        best_val_loss = loss_val[-1]
        counter = 0  # Reiniciamos el contador si hay mejora
  else:
        counter += 1  # Incrementamos el contador si no hay mejora

        # Si hemos alcanzado la paciencia, detenemos el entrenamiento
        if counter >= patience:
            print('Early stopping at epoch', epoch)
            break

end = time.time()
print('Finished Training, total time %f seconds' % (end - start))


# Graficar loss de entrenamiento Y validación
plt.figure(figsize = (8, 5))
plt.title('Modelo d loss on train & validation')
plt.xlabel('No. epochs')
plt.ylabel('Loss')
plt.plot(epochs, loss_train, 'b', label = 'Train')
plt.plot(epochs, loss_val, 'r', label = 'Validation')
plt.grid()
plt.legend()

# Obtener las predicciones en el conjunto de entrenamiento
modeld.eval()
all_predictions = []
all_labels = []

with torch.no_grad():
    for data in dataloader_train:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = modeld(inputs)
        _, predicted = torch.max(outputs, 1)
        all_predictions.extend(predicted.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# Calcular la matriz de confusión normalizada
conf_matrix = confusion_matrix(all_labels, all_predictions, normalize='true')

# Calcular el accuracy normalizado
normalized_accuracy = accuracy_score(all_labels, all_predictions)

# Mostrar la matriz de confusión con colores basados en el accuracy
def plot_confusion_matrix(matrix, accuracy, ax):
    sns.heatmap(matrix, annot=True, fmt='.2f', cmap='Blues', cbar=False, ax=ax)
    ax.set_xlabel('Predicted labels')
    ax.set_ylabel('True labels')
    ax.set_title(f'Normalized Confusion Matrix\nAccuracy train modelo d: {accuracy:.2f}')

# Graficar la matriz de confusión
plt.figure(figsize=(8, 6))
plot_confusion_matrix(conf_matrix, normalized_accuracy, plt.gca())
plt.show()

# Obtener las predicciones en el conjunto de validación
modeld.eval()
all_predictions_val = []
all_labels_val = []

with torch.no_grad():
    for data in dataloader_val:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = modeld(inputs)
        _, predicted = torch.max(outputs, 1)
        all_predictions_val.extend(predicted.cpu().numpy())
        all_labels_val.extend(labels.cpu().numpy())

# Calcular la matriz de confusión normalizada para el conjunto de validación
conf_matrix_val = confusion_matrix(all_labels_val, all_predictions_val, normalize='true')

# Calcular el accuracy normalizado para el conjunto de validación
normalized_accuracy_val = accuracy_score(all_labels_val, all_predictions_val)

# Función para mostrar la matriz de confusión con colores basados en el accuracy
def plot_confusion_matrix(matrix, accuracy, ax):
    sns.heatmap(matrix, annot=True, fmt='.2f', cmap='Blues', cbar=False, ax=ax)
    ax.set_xlabel('Predicted labels')
    ax.set_ylabel('True labels')
    ax.set_title(f'Normalized Confusion Matrix\nAccuracy eval modelo d: {accuracy:.2f}')

# Mostrar la matriz de confusión con colores basados en el accuracy para el conjunto de validación
plt.figure(figsize=(8, 6))
plot_confusion_matrix(conf_matrix_val, normalized_accuracy_val, plt.gca())
plt.show()

"""## Modelo e)"""

### Modelo e) ###

# -- Modelo de dos capas ocultas con 10 neuronas cada una y activación ReLU --
# Capa de entrada de 64 neuronas (porque hay 64 características)
# Capa oculta de 10 neuronas con activación ReLU
# Capa de salida de 10 neuronas (porque hay 10 clases)

modele = nn.Sequential(
    nn.Linear(64, 10),  # Primera capa oculta con 10 neuronas
    nn.ReLU(),  # Función de activación ReLU

    nn.Linear(10, 10),  # Segunda capa oculta con 10 neuronas
    nn.ReLU(),  # Función de activación ReLU

    nn.Linear(10, 10)  # Capa de salida con 10 neuronas
)

# Se le indica a Pytorch que correremos el modelo con GPU
device = "cuda" if torch.cuda.is_available() else "cpu"
modele = modele.to(device)

# Definimos la función de pérdida y optimizador usaremos
criterion = nn.CrossEntropyLoss()                         # Función de pérdida
optimizer = torch.optim.Adam(modele.parameters(), lr=1e-3) # Optimizador

start = time.time()

# Guardar resultados del loss y epocas que duró el entrenamiento
loss_train = []
loss_val = []
epochs = []

patience = 20  # Número de épocas para esperar antes de detener el entrenamiento, sacado a través de graficar 250 épocas
counter = 0     # Contador para llevar el registro de la paciencia
best_val_loss = float('inf')  # Inicializar el mejor loss de validación con un valor infinito

# Entrenamiento de la red por n epocas
for epoch in range(1000):

  # Guardar loss de cada batch
  loss_train_batches = []
  loss_val_batches = []


  # Entrenamiento --------------------------------------------------------------
  modele.train()
  # Debemos recorrer cada batch (lote de los datos)
  for i, data in enumerate(dataloader_train, 0):
    # Procesar batch actual
    inputs = data["features"].to(device) # Características
    labels = data["labels"].to(device)   # Clases
    # zero the parameter gradients
    optimizer.zero_grad()
    # forward + backward + optimize
    outputs = modele(inputs)           # Predicciones
    loss = criterion(outputs, labels) # Loss de entrenamiento
    loss.backward()                   # Backpropagation
    optimizer.step()

    # Guardamos la pérdida de entrenamiento y el accuracy en el batch actual
    loss_train_batches.append(loss.item())

  # Guardamos el loss de entrenamiento de la época actual
  loss_train.append(np.mean(loss_train_batches)) # Loss promedio de los batches

  # Predicción en conjunto de validación ---------------------------------------
  modele.eval()
  with torch.no_grad():
    # Iteramos dataloader_val para evaluar el modelo en los datos de validación
    for i, data in enumerate(dataloader_val, 0):
      # Procesar batch actual
      inputs = data["features"].to(device) # Características
      labels = data["labels"].to(device)   # Clases

      outputs = modele(inputs)              # Obtenemos predicciones

      # Guardamos la pérdida de validación en el batch actual
      loss = criterion(outputs, labels)
      loss_val_batches.append(loss.item())

  # Guardamos el Loss de validación de la época actual
  loss_val.append(np.mean(loss_val_batches)) # Loss promedio de los batches

  # Guardamos la época
  epochs.append(epoch)

  # Imprimir la pérdida de entrenamiento/validación en la época actual
  print(("Epoch: %d, train loss: %.4f, val loss: %.4f"  %(epoch, loss_train[epoch], loss_val[epoch])))

  # Tenemos el loss de entrenamiento y validación, ¿Como sería el early-stopping?
  # Verificamos si el loss de validación mejora
  if loss_val[-1] < best_val_loss:
        best_val_loss = loss_val[-1]
        counter = 0  # Reiniciamos el contador si hay mejora
  else:
        counter += 1  # Incrementamos el contador si no hay mejora

        # Si hemos alcanzado la paciencia, detenemos el entrenamiento
        if counter >= patience:
            print('Early stopping at epoch', epoch)
            break

end = time.time()
print('Finished Training, total time %f seconds' % (end - start))


# Graficar loss de entrenamiento Y validación
plt.figure(figsize = (8, 5))
plt.title('Modelo e loss on train & validation')
plt.xlabel('No. epochs')
plt.ylabel('Loss')
plt.plot(epochs, loss_train, 'b', label = 'Train')
plt.plot(epochs, loss_val, 'r', label = 'Validation')
plt.grid()
plt.legend()

# Obtener las predicciones en el conjunto de entrenamiento
modele.eval()
all_predictions = []
all_labels = []

with torch.no_grad():
    for data in dataloader_train:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = modele(inputs)
        _, predicted = torch.max(outputs, 1)
        all_predictions.extend(predicted.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# Calcular la matriz de confusión normalizada
conf_matrix = confusion_matrix(all_labels, all_predictions, normalize='true')

# Calcular el accuracy normalizado
normalized_accuracy = accuracy_score(all_labels, all_predictions)

# Mostrar la matriz de confusión con colores basados en el accuracy
def plot_confusion_matrix(matrix, accuracy, ax):
    sns.heatmap(matrix, annot=True, fmt='.2f', cmap='Blues', cbar=False, ax=ax)
    ax.set_xlabel('Predicted labels')
    ax.set_ylabel('True labels')
    ax.set_title(f'Normalized Confusion Matrix\nAccuracy train modelo e: {accuracy:.2f}')

# Graficar la matriz de confusión
plt.figure(figsize=(8, 6))
plot_confusion_matrix(conf_matrix, normalized_accuracy, plt.gca())
plt.show()

# Obtener las predicciones en el conjunto de validación
modele.eval()
all_predictions_val = []
all_labels_val = []

with torch.no_grad():
    for data in dataloader_val:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = modele(inputs)
        _, predicted = torch.max(outputs, 1)
        all_predictions_val.extend(predicted.cpu().numpy())
        all_labels_val.extend(labels.cpu().numpy())

# Calcular la matriz de confusión normalizada para el conjunto de validación
conf_matrix_val = confusion_matrix(all_labels_val, all_predictions_val, normalize='true')

# Calcular el accuracy normalizado para el conjunto de validación
normalized_accuracy_val = accuracy_score(all_labels_val, all_predictions_val)

# Función para mostrar la matriz de confusión con colores basados en el accuracy
def plot_confusion_matrix(matrix, accuracy, ax):
    sns.heatmap(matrix, annot=True, fmt='.2f', cmap='Blues', cbar=False, ax=ax)
    ax.set_xlabel('Predicted labels')
    ax.set_ylabel('True labels')
    ax.set_title(f'Normalized Confusion Matrix\nAccuracy eval modelo e: {accuracy:.2f}')

# Mostrar la matriz de confusión con colores basados en el accuracy para el conjunto de validación
plt.figure(figsize=(8, 6))
plot_confusion_matrix(conf_matrix_val, normalized_accuracy_val, plt.gca())
plt.show()

"""## Modelo f"""

### Modelo f) ###

# -- Modelo de dos capas ocultas con 40 neuronas cada una y activación ReLU --
# Capa de entrada de 64 neuronas (porque hay 64 características)
# Capa oculta de 40 neuronas con activación ReLU
# Capa de salida de 10 neuronas (porque hay 10 clases)

modelf = nn.Sequential(
    nn.Linear(64, 40),  # Primera capa oculta con 10 neuronas
    nn.ReLU(),  # Función de activación ReLU

    nn.Linear(40, 40),  # Segunda capa oculta con 10 neuronas
    nn.ReLU(),  # Función de activación ReLU

    nn.Linear(40, 10)  # Capa de salida con 10 neuronas
)

# Se le indica a Pytorch que correremos el modelo con GPU
device = "cuda" if torch.cuda.is_available() else "cpu"
modelf = modelf.to(device)

# Definimos la función de pérdida y optimizador usaremos
criterion = nn.CrossEntropyLoss()                         # Función de pérdida
optimizer = torch.optim.Adam(modelf.parameters(), lr=1e-3) # Optimizador

start = time.time()

# Guardar resultados del loss y epocas que duró el entrenamiento
loss_train = []
loss_val = []
epochs = []

patience = 8  # Número de épocas para esperar antes de detener el entrenamiento, sacado a través de graficar 250 épocas
counter = 0     # Contador para llevar el registro de la paciencia
best_val_loss = float('inf')  # Inicializar el mejor loss de validación con un valor infinito

# Entrenamiento de la red por n epocas
for epoch in range(1000):

  # Guardar loss de cada batch
  loss_train_batches = []
  loss_val_batches = []


  # Entrenamiento --------------------------------------------------------------
  modelf.train()
  # Debemos recorrer cada batch (lote de los datos)
  for i, data in enumerate(dataloader_train, 0):
    # Procesar batch actual
    inputs = data["features"].to(device) # Características
    labels = data["labels"].to(device)   # Clases
    # zero the parameter gradients
    optimizer.zero_grad()
    # forward + backward + optimize
    outputs = modelf(inputs)           # Predicciones
    loss = criterion(outputs, labels) # Loss de entrenamiento
    loss.backward()                   # Backpropagation
    optimizer.step()

    # Guardamos la pérdida de entrenamiento y el accuracy en el batch actual
    loss_train_batches.append(loss.item())

  # Guardamos el loss de entrenamiento de la época actual
  loss_train.append(np.mean(loss_train_batches)) # Loss promedio de los batches

  # Predicción en conjunto de validación ---------------------------------------
  modelf.eval()
  with torch.no_grad():
    # Iteramos dataloader_val para evaluar el modelo en los datos de validación
    for i, data in enumerate(dataloader_val, 0):
      # Procesar batch actual
      inputs = data["features"].to(device) # Características
      labels = data["labels"].to(device)   # Clases

      outputs = modelf(inputs)              # Obtenemos predicciones

      # Guardamos la pérdida de validación en el batch actual
      loss = criterion(outputs, labels)
      loss_val_batches.append(loss.item())

  # Guardamos el Loss de validación de la época actual
  loss_val.append(np.mean(loss_val_batches)) # Loss promedio de los batches

  # Guardamos la época
  epochs.append(epoch)

  # Imprimir la pérdida de entrenamiento/validación en la época actual
  print(("Epoch: %d, train loss: %.4f, val loss: %.4f"  %(epoch, loss_train[epoch], loss_val[epoch])))

  # Tenemos el loss de entrenamiento y validación, ¿Como sería el early-stopping?
  # Verificamos si el loss de validación mejora
  if loss_val[-1] < best_val_loss:
        best_val_loss = loss_val[-1]
        counter = 0  # Reiniciamos el contador si hay mejora
  else:
        counter += 1  # Incrementamos el contador si no hay mejora

        # Si hemos alcanzado la paciencia, detenemos el entrenamiento
        if counter >= patience:
            print('Early stopping at epoch', epoch)
            break

end = time.time()
print('Finished Training, total time %f seconds' % (end - start))


# Graficar loss de entrenamiento Y validación
plt.figure(figsize = (8, 5))
plt.title('Modelo f loss on train & validation')
plt.xlabel('No. epochs')
plt.ylabel('Loss')
plt.plot(epochs, loss_train, 'b', label = 'Train')
plt.plot(epochs, loss_val, 'r', label = 'Validation')
plt.grid()
plt.legend()

# Obtener las predicciones en el conjunto de entrenamiento
modelf.eval()
all_predictions = []
all_labels = []

with torch.no_grad():
    for data in dataloader_train:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = modelf(inputs)
        _, predicted = torch.max(outputs, 1)
        all_predictions.extend(predicted.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# Calcular la matriz de confusión normalizada
conf_matrix = confusion_matrix(all_labels, all_predictions, normalize='true')

# Calcular el accuracy normalizado
normalized_accuracy = accuracy_score(all_labels, all_predictions)

# Mostrar la matriz de confusión con colores basados en el accuracy
def plot_confusion_matrix(matrix, accuracy, ax):
    sns.heatmap(matrix, annot=True, fmt='.2f', cmap='Blues', cbar=False, ax=ax)
    ax.set_xlabel('Predicted labels')
    ax.set_ylabel('True labels')
    ax.set_title(f'Normalized Confusion Matrix\nAccuracy train modelo f: {accuracy:.2f}')

# Graficar la matriz de confusión
plt.figure(figsize=(8, 6))
plot_confusion_matrix(conf_matrix, normalized_accuracy, plt.gca())
plt.show()

# Obtener las predicciones en el conjunto de validación
modelf.eval()
all_predictions_val = []
all_labels_val = []

with torch.no_grad():
    for data in dataloader_val:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = modelf(inputs)
        _, predicted = torch.max(outputs, 1)
        all_predictions_val.extend(predicted.cpu().numpy())
        all_labels_val.extend(labels.cpu().numpy())

# Calcular la matriz de confusión normalizada para el conjunto de validación
conf_matrix_val = confusion_matrix(all_labels_val, all_predictions_val, normalize='true')

# Calcular el accuracy normalizado para el conjunto de validación
normalized_accuracy_val = accuracy_score(all_labels_val, all_predictions_val)

# Función para mostrar la matriz de confusión con colores basados en el accuracy
def plot_confusion_matrix(matrix, accuracy, ax):
    sns.heatmap(matrix, annot=True, fmt='.2f', cmap='Blues', cbar=False, ax=ax)
    ax.set_xlabel('Predicted labels')
    ax.set_ylabel('True labels')
    ax.set_title(f'Normalized Confusion Matrix\nAccuracy eval modelo f: {accuracy:.2f}')

# Mostrar la matriz de confusión con colores basados en el accuracy para el conjunto de validación
plt.figure(figsize=(8, 6))
plot_confusion_matrix(conf_matrix_val, normalized_accuracy_val, plt.gca())
plt.show()

"""## Mejor modelo"""

# Como el mejor modelo es el modelo b, que tiene mayor accuracy y menor loss en el conjunto de validación, se calcula la matriz de confusión
#normalizada y el accuracy normalizado, usando el conjunto de prueba.

# Inicializar listas para guardar las predicciones y etiquetas verdaderas
all_predictions_test = []
all_labels_test = []

# Poner el modelo en modo de evaluación
modelb.eval()

with torch.no_grad():
    for data in dataloader_test:   #conjunto de prueba
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = modelb(inputs)
        _, predicted = torch.max(outputs, 1)
        all_predictions_test.extend(predicted.cpu().numpy())
        all_labels_test.extend(labels.cpu().numpy())

# Calcular la matriz de confusión para el conjunto de prueba
conf_matrix_test = confusion_matrix(all_labels_test, all_predictions_test, normalize='true')

# Calcular el accuracy para el conjunto de prueba
normalized_accuracy_test = accuracy_score(all_labels_test, all_predictions_test)

# Función para mostrar la matriz de confusión con colores basados en el accuracy
def plot_confusion_matrix(matrix, accuracy, ax):
    sns.heatmap(matrix, annot=True, fmt='.2f', cmap='Blues', cbar=False, ax=ax)
    ax.set_xlabel('Predicted labels')
    ax.set_ylabel('True labels')
    ax.set_title(f'Normalized Confusion Matrix\nAccuracy test modelo b: {accuracy:.2f}')

# Mostrar la matriz de confusión con colores basados en el accuracy para el conjunto de validación
plt.figure(figsize=(8, 6))
plot_confusion_matrix(conf_matrix_test, normalized_accuracy_test, plt.gca())
plt.show()